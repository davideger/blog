{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Public Google Colab - Synthetic Reviews Dataframe Benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LCEH5ap9r2Ne"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBNDJbMZXp5n"
      },
      "source": [
        "# Review Selection, a small dataframe benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nhkgh_QXzcL"
      },
      "source": [
        "Problem: Populate part of a \"reviews\" section for a restaurant listing page.  We tackle two tasks:\n",
        "\n",
        "a. Select a few diverse reviews to show on the first page.\n",
        "b. Calculate this restaurant's rank vs all other restaurants for\n",
        "   each rating aspect: \"atmosphere\", \"food\", \"speed\", \"location\", and \"friendliness.\"\n",
        "\n",
        "The number of reviews per restaurant follows a Zipfian distribution, with the top restaurants having ~1k reviews, the average head restaurant having ~50 reviews, and a very long tail with only 1 or 2 reviews.\n",
        "\n",
        "When serving the first set of reviews for a particular restaurant, you want to serve up informative reviews from users who had different opinions about how good the restaurant was, and why they thought so.  We will treat this problem by choosing a few reviews for each star rating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04swN9-BYdyy"
      },
      "source": [
        "## Prelude / loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQDRk02TXlTe"
      },
      "source": [
        "!pip install pandas numpy\n",
        "!pip install polars\n",
        "!pip install pyarrow\n",
        "!pip install ray[default]\n",
        "!pip install 'fsspec>=0.3.3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlOExARYbjv"
      },
      "source": [
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import platform\n",
        "import pyarrow\n",
        "from functools import partial\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "#os.environ[\"RUST_BACKTRACE\"] = \"1\"\n",
        "#os.environ[\"RUST_BACKTRACE\"] = \"full\"\n",
        "\n",
        "def diagnose_me():\n",
        "  print(f\"Python {platform.python_version()}\")\n",
        "  for (name, pkg) in [(\"Pandas\", pd), (\"NumPy\", np), (\"Polars\", pl), (\"PyArrow\", pyarrow)]:\n",
        "    print(f\"{name}: {pkg.__version__}\")\n",
        "\n",
        "\n",
        "diagnose_me()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGmlDC0LPCd4"
      },
      "source": [
        "## Synthetic Reviews generation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUB4VmbDq5S6"
      },
      "source": [
        "from numpy.random import default_rng\n",
        "rng = default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnVKnGOUFHo"
      },
      "source": [
        "def multinomial_selection(choices, ps, num_samples):\n",
        "  \"\"\"Choose num_samples from among the given choices according to the given probabilities.\"\"\"\n",
        "  return np.array(choices)[np.argmax(rng.multinomial(1, ps, size=num_samples), axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uofs3gfiUfH1"
      },
      "source": [
        "multinomial_selection([\"beer\", \"brats\", \"coffee\"], [.8, .19, .01], 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVLhinqa98_"
      },
      "source": [
        "def get_stars(restaurant_quality=0., num_reviews=30):\n",
        "  \"\"\"Return a distribution of star ratings (1-5) for a given restaurant.\n",
        "\n",
        "  \"\"\"\n",
        "  restaurant_distributions = [\n",
        "    [.2, .34, .35, .1, .01],   # poor restaurant                          \n",
        "    [.1, .15, .1, .6, .05],    # typical restaurant\n",
        "    [.01, .0, .01, .08, .90],  # great restaurant\n",
        "  ]\n",
        "  dist_idx = np.clip(restaurant_quality * 3., 0, 2).astype(int)\n",
        "  return np.argmax(rng.multinomial(1, restaurant_distributions[dist_idx], size=num_reviews), axis=1) + 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp_lzrD_fB_J"
      },
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
        "_ = axs[0].hist(get_stars(restaurant_quality = .1), range=(1., 5.))\n",
        "_ = axs[1].hist(get_stars(restaurant_quality = .6), range=(1., 5.))\n",
        "_ = axs[2].hist(get_stars(restaurant_quality = .9), range=(1., 5.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu1VNBSxm1_Q"
      },
      "source": [
        "def get_review_quality(word_counts):\n",
        "  \"\"\"Return a distribution of textual quality (0. - 1.) for reviews with\n",
        "  the given word counts.\n",
        "\n",
        "  \"\"\"\n",
        "  quality_distributions = [\n",
        "    [1., 0., 0., 0., 0.],      # short reviews\n",
        "    [.1, .15, .1, .6, .05],    # medium reviews\n",
        "    [.01, .0, .01, .08, .90],  # long reviews\n",
        "  ]\n",
        "  dist_indices = np.searchsorted([2, 120], word_counts)\n",
        "  return np.clip( np.array(\n",
        "    [np.argmax(rng.multinomial(1, quality_distributions[dist_idx])) / 4. for dist_idx in dist_indices]\n",
        "  ) + (rng.random(len(word_counts)) * .25), 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTtWx48FhOnm"
      },
      "source": [
        "def get_age_weeks(num_reviews=20):\n",
        "  max_age_weeks = 1017\n",
        "  jitter_weeks = 26\n",
        "  return np.clip(np.random.zipf(1.6, num_reviews), 1, max_age_weeks - jitter_weeks) + np.random.randint(0, jitter_weeks, num_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOIDJANgNr6"
      },
      "source": [
        "_ = plt.hist(get_age_weeks(100), range=(0,120))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgwPk6eblAKL"
      },
      "source": [
        "def random_choice(choices, num_reviews):\n",
        "  return np.choose(np.random.randint(0, len(choices), num_reviews),\n",
        "                   np.array(choices))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8UGmYojCgW"
      },
      "source": [
        "review_aspects = [\"atmosphere\", \"food\", \"speed\", \"location\", \"friendliness\"]\n",
        "def get_topic(num_reviews):\n",
        "  return random_choice(review_aspects,\n",
        "                       num_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcwLzCGrYdA-"
      },
      "source": [
        "def generate_synthetic_review(restaurant_quality, num_reviews):\n",
        "  # stars               - 1-5\n",
        "  # reviewer_id         - int\n",
        "  # review_age_weeks    - int >= 0\n",
        "  # review_month        - int (1-12)\n",
        "  # primary_topic       - string (categorical: atmosphere, food, speed, location, friendliness)\n",
        "  # kids_involved       - bool\n",
        "  # for_business        - bool\n",
        "  # text_length         - int (word count)\n",
        "  # text_quality        - float (0.0 - 1.0)\n",
        "  # language            - string (2-letter language code)\n",
        "  stars            = get_stars(restaurant_quality, num_reviews)\n",
        "  reviewer_id      = np.random.randint(1000, 9999, num_reviews)\n",
        "  review_age_weeks = get_age_weeks(num_reviews)\n",
        "  review_month     = np.ones(num_reviews) * 12 - np.mod(review_age_weeks, 12)\n",
        "  primary_topic    = get_topic(num_reviews)\n",
        "  kids_involved    = np.random.binomial(1, .2, num_reviews).astype(bool)\n",
        "  for_business     = np.random.binomial(1, .4, num_reviews).astype(bool) & ~kids_involved\n",
        "  kids_involved    = [bool(x) for x in kids_involved]\n",
        "  for_business     = [bool(x) for x in for_business]\n",
        "  text_length      = np.random.randint(0, 300, num_reviews)\n",
        "  text_quality     = get_review_quality(text_length)\n",
        "  language         = multinomial_selection([\"en\", \"es\", \"fr\"],\n",
        "                                           [.4, .1, .05],\n",
        "                                           num_reviews)\n",
        "  rv = {}\n",
        "  for v in [\"stars\", \"reviewer_id\", \"review_age_weeks\", \"review_month\",\n",
        "            \"primary_topic\", \"kids_involved\", \"for_business\", \"text_length\",\n",
        "            \"text_quality\", \"language\"]:\n",
        "            rv[v] = locals()[v]\n",
        "  return rv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn4spD0LfmN-"
      },
      "source": [
        "def generate_synthetic_reviews_dataset(num_listings=5000):\n",
        "  num_reviews = rng.zipf(2, num_listings)\n",
        "  restaurant_goodness = rng.random(num_listings)\n",
        "  reviews_dfs = []\n",
        "  reviews_pls = []\n",
        "  for i in range(num_listings):\n",
        "    data = generate_synthetic_review(restaurant_goodness[i], num_reviews[i])\n",
        "    reviews_dfs.append(pd.DataFrame(data))\n",
        "    npl = pl.DataFrame(data)\n",
        "    npl['index'] = pl.Series('index', list(range(num_reviews[i])))\n",
        "    reviews_pls.append(npl)\n",
        "  return reviews_dfs, reviews_pls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCEH5ap9r2Ne"
      },
      "source": [
        "# Aspect Ranking Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWNnX91Zr5lM"
      },
      "source": [
        "# First, we generate a set of test data\n",
        "reviews_dfs, reviews_pls = generate_synthetic_reviews_dataset(25000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9DqEK7FnnzD"
      },
      "source": [
        "def pd_calculate_per_aspect_star_rating(reviews):\n",
        "  star_prior = 3.0\n",
        "  default_reviews = pd.DataFrame({'primary_topic': review_aspects,\n",
        "                                  'stars': [star_prior] * len(review_aspects)})\n",
        "  return pd.concat([reviews[['primary_topic', 'stars']], default_reviews]).groupby('primary_topic').mean().transpose()\n",
        "\n",
        "pd_calculate_per_aspect_star_rating(reviews_dfs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OukEiPzeo5iE"
      },
      "source": [
        "def pd_get_aspect_ratings_for_listings(pd_reviews_per_listing):\n",
        "  rating_summaries = []\n",
        "  for i in range(len(pd_reviews_per_listing)):\n",
        "    ratings = pd_calculate_per_aspect_star_rating(pd_reviews_per_listing[i])\n",
        "    rating_summaries.append(ratings)\n",
        "  return pd.concat(rating_summaries, axis=0)\n",
        "\n",
        "pd_listing_aspect_ratings = pd_get_aspect_ratings_for_listings(reviews_dfs)\n",
        "pd_listing_aspect_ratings.head(n=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1WK6RP37fm0"
      },
      "source": [
        "def pd_get_aspect_ranks_speedy(pd_listing_aspect_ratings):\n",
        "  \"\"\"Return the rank of this listing globally for a given aspect.\"\"\"\n",
        "  # Note - this code is purposefully a bit inefficient to show\n",
        "  # an outsized slowdown below.\n",
        "  num_listings = pd_listing_aspect_ratings.shape[0]\n",
        "  ordered = {}\n",
        "  for col in pd_listing_aspect_ratings.columns:\n",
        "    ordered[col] = pd_listing_aspect_ratings[col].sort_values()\n",
        "  def get_ranks(listing_id):\n",
        "    listing_ratings = pd_listing_aspect_ratings.iloc[listing_id]\n",
        "    rv = {}\n",
        "    for aspect in review_aspects:\n",
        "      rv[aspect] = [num_listings - np.searchsorted(ordered[aspect], listing_ratings[aspect], side='right')]\n",
        "    return pd.DataFrame(rv)\n",
        "  return get_ranks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2byH5EP771NC"
      },
      "source": [
        "rank_getter = pd_get_aspect_ranks_speedy(pd_listing_aspect_ratings)\n",
        "%timeit rank_getter(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La7J2w8uO69V"
      },
      "source": [
        "def get_aspect_rank_descriptions(listing_id, num_listings, get_aspect_ranks_fn):\n",
        "  dl = get_aspect_ranks_fn(listing_id)\n",
        "  rank_descriptions = [\n",
        "      f\"#{dl.loc[0, aspect]} out of {num_listings} for {aspect}\"\n",
        "      for aspect in dl.columns]\n",
        "  return \"; \".join(rank_descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNc8-9GJtie9"
      },
      "source": [
        "print(get_aspect_rank_descriptions(10,\n",
        "                                   len(pd_listing_aspect_ratings),\n",
        "                                   partial(pd_get_aspect_ranks_slower, pd_listing_aspect_ratings)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5hpSQ2rfgB8"
      },
      "source": [
        "# Benchmarking Polars against Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_w0VZQtdRoH"
      },
      "source": [
        "# Here are two versions of a groupby+head+sort for benchmarking,\n",
        "# one set in Polars (pl) and another in Pandas (pd)\n",
        "def pd_get_representative_reviews(df, depth=2):\n",
        "  return df[df.language == 'en'].sort_values(by=['stars', 'review_age_weeks']).groupby('stars').head(depth).index\n",
        "\n",
        "print(f\"Pandas: Getting representative reviews at 3 depths for {len(reviews_dfs)} listings.\")\n",
        "%time _ = [pd_get_representative_reviews(x, d) for x in reviews_dfs for d in [1,3,9]]\n",
        "\n",
        "def pl_get_representative_reviews(df, depth=2):\n",
        "  return df[df.language == 'en'].sort(['stars', 'review_age_weeks']).groupby('stars').head(depth).sort(['stars', 'review_age_weeks']).index\n",
        "\n",
        "print(f\"Polars: Getting representative reviews at 3 depths for {len(reviews_pls)} listings.\")\n",
        "%time _ = [pl_get_representative_reviews(x) for x in reviews_pls for d in [1,3,9]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YejRzNjCtZjd"
      },
      "source": [
        "On a two-core Google colab instance, `Polars` takes a total of `5.1s` whereas `Pandas` takes a total of `17.9s`.  This is great!  However, on a 12 core workstation we see a *slowdown.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9i2F82yXB7g"
      },
      "source": [
        "import psutil\n",
        "\n",
        "def process_listing(df,\n",
        "                    listing_id,\n",
        "                    get_reviews_fn, depth,\n",
        "                    get_ranks_description_fn):\n",
        "  rv = {'df': df, 'listing_id': listing_id}\n",
        "  best_reviews = get_reviews_fn(df, depth)\n",
        "  ranks_description = get_ranks_description_fn(listing_id)\n",
        "  rv['cpu_id'] = psutil.Process().cpu_num()\n",
        "  rv['html'] = (f'Listing {listing_id}:: {ranks_description}\\n' +\n",
        "                f'Be sure to check out reviews {best_reviews}')\n",
        "  return rv                     \n",
        "                                \n",
        "  \n",
        "def pd_process_listing(df, listing_id, depth, get_ranks_description_fn):\n",
        "  return process_listing(df, listing_id, pd_get_representative_reviews, depth, get_ranks_description_fn)\n",
        "      \n",
        "      \n",
        "def pl_process_listing(df, listing_id, depth, get_ranks_description_fn):\n",
        "  return process_listing(df, listing_id, pl_get_representative_reviews, depth, get_ranks_description_fn)\n",
        "\n",
        "\n",
        "bmsize=25000                    \n",
        "pandas_reviews, polars_reviews = generate_synthetic_reviews_dataset(bmsize)\n",
        "  \n",
        "# This aspect rank finder is somewhat memory intensive using about 1MB \n",
        "# of precomputed data as reference to demonstrate an interesting problem\n",
        "# with multi-core machines.\n",
        "pd_listing_aspect_ratings = pd_get_aspect_ratings_for_listings(pandas_reviews)\n",
        "fast_ranker = pd_get_aspect_ranks_speedy(pd_listing_aspect_ratings)\n",
        "\n",
        "\n",
        "def noop_description_maker(listing_id):\n",
        "  return \"This place is fast!\"\n",
        "\n",
        "\n",
        "def fast_rank_description_maker(listing_id):\n",
        "  return get_aspect_rank_descriptions(listing_id, bmsize, fast_ranker)\n",
        "\n",
        "\n",
        "def cpu_history(processed_listings):\n",
        "  # a is an array of cpu ids in (presumably) program order.\n",
        "  a = [r[\"cpu_id\"] for r in processed_listings]\n",
        "  num_core_changes = ((a - np.roll(a,1) ) != 0.).astype(int).sum()\n",
        "  return f\"Over {len(a)} records, computation jumped core at least {num_core_changes} times.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOvHZR0NPeeo"
      },
      "source": [
        " On a 2 core public Google colab instance, the Polars version *just runs faster*.  However, try loading the same code onto a monster multi-core machine...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ayjWHCQHju"
      },
      "source": [
        "import timeit\n",
        "for (label, postprocessing) in [('no post processing', noop_description_maker),\n",
        "                                ('rank finding', fast_rank_description_maker),\n",
        "                                ]:\n",
        "  print(f'Pandas finding representative reviews for {bmsize} synthetic listings + {label}')\n",
        "  %time pandas_results = [process_listing(df, listing_id, pd_get_representative_reviews, d, postprocessing) for (listing_id, df) in enumerate(pandas_reviews) for d in [1,3,9]]\n",
        "\n",
        "print(f\"CPU History: {cpu_history(pandas_results)}\")\n",
        "\n",
        "for (label, postprocessing) in [('no post processing', noop_description_maker),\n",
        "                                ('rank finding', fast_rank_description_maker)\n",
        "                               ]:\n",
        "  print(f'Polars finding representative reviews for {bmsize} synthetic listings + {label}')\n",
        "  %time polars_results = [process_listing(df, listing_id, pl_get_representative_reviews, d, postprocessing) for (listing_id, df) in enumerate(polars_reviews) for d in [1,3,9]]\n",
        "\n",
        "print(f\"CPU History: {cpu_history(polars_results)}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}